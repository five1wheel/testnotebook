**Attention Is All You Need**阅读

牧神阅读文章的顺序

![image-20231227201628100](D:\Work_APP\Typora\assets\image-20231227201628100.png)

摘要部分

![image-20231227201736237](D:\Work_APP\Typora\assets\image-20231227201736237.png)

卷积神经网络或者复杂的循环，包括编码器，解码器，28.4BLEU机器翻译，英语到德语，英语到法语。机器翻译的。

![image-20231227202314001](D:\Work_APP\Typora\assets\image-20231227202314001.png)

循环层，多头自注意力机制层，可以用在文本外的文件上，生成不那么时序化

![image-20231227202618435](D:\Work_APP\Typora\assets\image-20231227202618435.png)

![image-20231227202711033](D:\Work_APP\Typora\assets\image-20231227202711033.png)

时序里面LSTM，语言模型，编码器解码器

RNN,ht和ht-1之前状态放在隐藏状态，不易并行，算ht时候，得先算完ht-1。

Attention,主要把编码器的东西有效的传递给解码器。纯用attention，提高并行。

![image-20231227203225015](D:\Work_APP\Typora\assets\image-20231227203225015.png)



相关工作，使用卷积神经网络替换掉循环神经网络，减少计算量，卷积神经网络去做长的序列比较难以建模，卷积计算的时候用一个比较小的卷积块，像素隔得比较远的时候需要用多层卷积。一层一层的最后才能把隔的比较远的像素融合起来。如果使用Transformer，模拟卷积神经网络多输出通道的效果，还讲了自注意力机制。

![image-20231227203727955](D:\Work_APP\Typora\assets\image-20231227203727955.png)

n和m不一样，比如中文翻译英文句子长度就不一样，翻译句子的时候，在编码的时候能够一下看到完整的句子，而解码器只能一个个翻译，这玩意叫自回归'auto-regressivet，你的输出优势你的输入

在最开始的Z1要生成y1

![image-20231227205025262](D:\Work_APP\Typora\assets\image-20231227205025262.png)









![image-20231227205558442](D:\Work_APP\Typora\assets\image-20231227205558442.png)

512每一个层都是，使得模型相对比较简单，调的参数也比较少只有两个N和d~model~

解释一下LayerNorm，对比batchNorm

<img src="D:\Work_APP\Typora\assets\image-20231227205807904.png" alt="image-20231227205807904" style="zoom:50%;" />

1.batchnorm干的事情

<img src="D:\Work_APP\Typora\assets\image-20231227205953984.png" alt="image-20231227205953984" style="zoom:50%;" />

<img src="D:\Work_APP\Typora\assets\image-20231227210400123.png" alt="image-20231227210400123" style="zoom: 25%;" />

​        每一个列把它的均值变0方差变1，概率论里面那个正态标准化，并且batchnorm能够学习，并把某个列变成均值、方差为某个东西的。切一块出来，拉成一个向量

2.Layernorm

每一行是batch{1,2..n},每一列是feature{1,2,...,m}

<img src="D:\Work_APP\Typora\assets\image-20231227210134931.png" alt="image-20231227210134931" style="zoom:25%;" />

<img src="D:\Work_APP\Typora\assets\image-20231227210457882.png" alt="image-20231227210457882" style="zoom: 25%;" />

他就是整个转置一下，放到batchnorm里面出来的结果再转置回来。

三维情况下，输出是序列的样本。

layernorm用的多的原因，是时序的样本长度不一样

- <img src="D:\Work_APP\Typora\assets\image-20231227210601165.png" alt="image-20231227210601165" style="zoom:25%;" />

  batchnorm切除来的东西，算均值的时候就是阴影部分，在下批量样本长度相差比较大的时候，做均值和方差的抖动比较大

- <img src="D:\Work_APP\Typora\assets\image-20231227210624206.png" alt="image-20231227210624206" style="zoom:25%;" />

  <img src="D:\Work_APP\Typora\assets\image-20231227210744000.png" alt="image-20231227210744000" style="zoom:25%;" />

  layernorm切除来的东西，是对每个样本来做的，算均值是在样本自己里算的

- <img src="D:\Work_APP\Typora\assets\image-20231227210709646.png" alt="image-20231227210709646" style="zoom:25%;" />

  <img src="D:\Work_APP\Typora\assets\image-20231227211146694.png" alt="image-20231227211146694" style="zoom: 25%;" />

  解码器：

  ![image-20231227211217682](D:\Work_APP\Typora\assets\image-20231227211217682.png)

带掩码的masked的多头注意力机制模块，在t个时刻的时候你不应该看到t时刻以后的那些输入，保持训练和预测的时候性能一致。

## 注意力机制的计算

![image-20231227211438406](D:\Work_APP\Typora\assets\image-20231227211438406.png)

形象一点的理解：<u>key相当于名字，value是分数，query表示我想看谁的分数</u>，所以通过query去查key对应的value，获得最终的结果

query查询，key键，value值。查询来自用户输入，键来自词典库，将查询与键（二者属性相同可比较），得到相似度权重，由value可数值化运算

output=value的加权和，权重=每个value对应的key和查询的query的相似度计算而来

![image-20231227214045216](D:\Work_APP\Typora\assets\image-20231227214045216.png)

![image-20231227214205423](D:\Work_APP\Typora\assets\image-20231227214205423.png)

对每个query和每个key做内积，如过两个向量的长度一样，内积的值越大，两个向量的相似度越大，

放进softmax会得到一些非负的相加等于的权重，然后把权重分配。



<img src="D:\Work_APP\Typora\assets\image-20231227215621136.png" alt="image-20231227215621136" style="zoom:50%;" />



![image-20231227215544666](D:\Work_APP\Typora\assets\image-20231227215544666.png)

对于一组key、value对和n个query，可以通过两次矩阵乘法来把整个矩阵乘法做掉。矩阵乘法的好并行性。两种注意力机制，一种是加性的，可以处理key和query不等长的情况，另外一种是点积注意力机制，为啥要除以根号dk，类似一个归一化，为了避免数据向两端靠拢，当你算梯度的时候，会发现梯度比较小。softmax的结果希望置信的地方尽量靠近1，不置信的地方尽量靠近0。就会跑不动。

<img src="D:\Work_APP\Typora\assets\image-20231227220141363.png" alt="image-20231227220141363" style="zoom:50%;" />

怎么做Mask，query、key是等长的，并且在时间上是能对应起来的，

<img src="D:\Work_APP\Typora\assets\image-20231227220308479.png" alt="image-20231227220308479" style="zoom:50%;" />

在计算权重输出的时候不要用到t...n这些时刻的时候，处理方式，就是针对（Q、K）t...n这些时刻的那些值，把它换成很大的复数，-11^10，然后把这些复数放进去做指数的时候都会变成0，只会有前面的时刻的那些值。

## Multi-Head Attention是啥？

<img src="D:\Work_APP\Typora\assets\image-20231227220643253.png" alt="image-20231227220643253" style="zoom:50%;" />

与其做单个的注意力函数，不如把key、query、value这些投影到一个低维，投影h次，然后再做h次的注意力函数，然后每一个函数的输出把它并在一起，然后再投影回来

<img src="D:\Work_APP\Typora\assets\image-20231227221232060.png" alt="image-20231227221232060" style="zoom:50%;" />

<img src="D:\Work_APP\Typora\assets\image-20231227221348625.png" alt="image-20231227221348625" style="zoom:50%;" />

Concat组合起来，h是8个头



## 使用注意力的情况



![image-20231227221708640](D:\Work_APP\Typora\assets\image-20231227221708640.png)输入输出![image-20231227221752481](D:\Work_APP\Typora\assets\image-20231227221752481.png)



<img src="D:\Work_APP\Typora\assets\image-20231227222235154.png" alt="image-20231227222235154" style="zoom:50%;" />![](D:\Work_APP\Typora\assets\image-20231227222459908.png)

![image-20231227222703271](D:\Work_APP\Typora\assets\image-20231227222703271.png)



编码器的输出是n个长为d的向量，mask也是m个长为d的向量，权重表示粗细程度，去有效的把编码器的一些东西，

根据解码器给的输入不一样，会在编码器中挑选感兴趣的部分

![image-20231229094210293](D:\Work_APP\Typora\assets\image-20231229094210293.png)

connected feed-forward network 实质上就是一个MLP多层感知器，区别是，position就是输入的每一个词，它就是把MLP对每一个词作用一次。

![image-20231229094516659](D:\Work_APP\Typora\assets\image-20231229094516659.png)

dff2048→dmodel512

第一个大红快是一个attention层，全局去拉信息，attention的作用就是把所有的输入做加权和，把整个序列的信息抓取出来做个汇聚。MLP的权重是一样的这边。

Transfromer没有layernorm，没有投影。

<img src="D:\Work_APP\Typora\assets\image-20240102215055134.png" alt="image-20240102215055134" style="zoom:50%;" />

RNN的示意

![image-20240102215738220](D:\Work_APP\Typora\assets\image-20240102215738220.png)

rnn和transform都是用一个MLP做一个语义空间转换（有效使用序列信息），不一样的是你如何传递信息，上面绿色的线代表之前的信息

