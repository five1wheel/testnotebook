基于两流2D CNN的方法

顾名思义，双流2DCNN框架通常包含了两个2D CNN分支，它们采用了从RGB视频中提取的不同输入特征用于HAR，通常通过融合策略得到最终结果，如图1(a)所示。在本节中，我们将回顾经典的两流方法，以及它们的扩展。

作为一个景点的双流框架，S和Z提出了一个由空间网络和时间网络组成的双流CNN模型。更具体的说，给定一个视频，每个单独的RGB帧和基于多帧的光流分别被输入到空间流和时间流中，因此这两个流在HAR中学习了外观特征和运动特征。最后，将这两个流的分数进行融合，生成最终分类结果，在另一项经典工作中K等人将低分辨率RGB帧和高分辨率中心裁剪两个独立的溜来加快计算速度，研究了不同的融合策略来模拟视频中的时间动态。一些研究视图扩展和改进这些经典的双流CNN。

为了为HAR生成更好的视频表示，W将多尺度视频帧和光流输入双流CNN提取卷积特征图，然后在以提取轨迹中心的时空管道上采样。最后，使用Fisher向量表示和支持向量机对得到的特征进行聚合。C等人利用人体关节位置，从RGB图像和光流图像裁剪出多个人体部位，通过双流网络进行特征提取，然后使用SVM分类器进行HAR。

还有其他几个作品，扩展了双流框架，提取了HAR的长期视频级信息，W将每个视频分成三个片段，并使用双流网络对每个片段进行处理。然后利用平均赤化方法将三个片段分类分数进行融合，生成视频级预测。D不想那样融合片段分数，而是通过元素惩罚来聚合片段特诊，G基于双流框架从采样的外观和运动帧中提取特征，并使用动作词将特征聚合成单个视频级表示进行分类。F等人将外观残差特征门控调制特征级运动信息相乘，Z等人通过加入运动显著流，将53中的双流CNN扩展成三流CNN，以更好地捕捉显著运动信息，B等人从RGB序列和光流序列构建动态图像，通过55秩赤化来总结长期全局外观和运动，然后将动态图像与原始

 

 

单深度图像中局部人体姿态的实时识别

 

鲁棒性的交互式人体跟踪应用包括游戏，人机交互、安全、远程呈现，甚至医疗保健。最近实时深度相机引入大大简化了这项任务。然而，即使最好的现有系统，也存在局限性。尤其值得一提的是，在Kinect发布之前，没有任何一款游戏能够在消费者硬件以交互速率运行，同时处理各种形状、尺寸的各种身体动作，有些系统通过逐帧跟踪来实现高速运行，但很难快速重新初始化，因此不够鲁邦。在本文中，我们专注于部分的姿态识别，从单个深度图中检测出每个骨骼关节的一个小3D位置候选集合。我们对每帧初始化和回复关注。旨在补充任何适当的跟踪算法。这些算法可能进一步纳入时间运动学一致性，本文提出算法构成了Kinect游戏平台的核心组件。

如图1所示最近期物体是被

 

 

 

基于自适应点云采样策略的连续三维人体姿态估计

带着问题去读，

\1. 自适应体现在哪

\2. 点云

摘要：基于点云的人体姿态估计任然存在噪声和估计抖动伪影，这主要是由于手工采集点云和采用单帧估计策略所致。本文提出了一种基于点云序列的三维人体姿态估计方法。为了对输入有效点云进行采样，我们设计了一种基于密度引导注意力机制的可微分点云采样，为了避免遗忘三维人体姿态估计问题引起的抖动，我们采用时间信息来获得更稳定的结果。在ITOP数据集和NTURGBD数据集上的实验表明，我们所提供的所有组件都是有效的，我们的方法可以达到最先进性能。

对于三维姿态估计输入，深度图或点云通常更可取。首先，点云包含了人体的三维空间信息，可以正确估计人体姿态尺度。其次，点云在光强变化的环境下质量一般不变，这导致了更多潜在应用场景，如室内增强现实。最后，深度传感器广泛应用于手机平板电脑，这需要强大算法来利用这些深度传感器。

挑战：1.噪声点云2.遮挡、自遮挡造成模糊性3.单帧姿态估计上，缺乏时间平滑增强，目前的方法可能在连续点云序列上产生晃动伪影。

本文提出了一种基于点云序列的三维人体姿态估计方法。受单帧基于点云的框架启发，我们使用点云序列设计了一种新的两阶段人体姿态估计通道。点云采集模块用于自适应地旋转有效点云，可以为人体姿态估计提供信息。为解决噪声点云问题，我们观察到点云采样测量可以提高输入点云质量。因此，我们首先基于密度引导注意李机制估计点云采样中心，并利用这些中心点对姿态感知点云进行采样。为了解决伪影和遮挡问题，我们使用时间一致性来约束结果，从而生成准确的人体姿态结果

\1. 介绍，基于点云的三维人体姿态是今年来的一个脊柱研究领域，他可以应用于人机交互、运动重定向和虚拟化身控制等多个领域。对于三维人体姿态估计的输入，深度图或点云通常更可取。首先，点云包含了人体的三维空间信息，可以是估计的人体姿态尺度正确。其次，点云在环境。

三个创新：

（1）提出了一种基于密度引导和注意的可微点云采样方法。选择人体前景中的点云，为姿态估计提供更有效的点云输入。

（2）提出一种基于时间序列的电源三维人体姿态估计方法，比现在的获得更好更平滑的人体姿态估计结果。

（3）构建一个试试的人体捕获系统，实现了人体运动馆的平稳捕捉

\2. 相关工作

2.1人体姿态估计

回顾使用单一图像作为输入的相关最新方法，以及利用时间信息的集中代表性的3D人体姿态估计方法。

对于深度图估计的3D，res2net

（1）利用统计模型从深度图估计人体姿态

（2）将深度图视为点云，并将其转换为3D体素网格;然后使用3D CNN来估计人体的3D姿势。

（3）首先使用RGB图像对点云进行体素化，并使用类似res2net的网络

![img](D:\Work_APP\Typora\assets\wps1.jpg) 

（4）来估计人体的3D姿势。

（5）[Zhang et al.， 2020]使用2D/3D混合表示深度图和类生成方法。

 

视频的三维人体姿态估计方法可分为两大类

第一种是使用之后的时间信息，并使用它来平滑估计结果。

（1）提出了一种多级序列细化网络来估计3D人体姿态序列。

（2）使用全连接网络来细化粗输入位姿。

（3）使用时间一致的2D姿势来估计3D姿势序列

第二种类型使用时间信息并从序列中提取与时间相关的特征。

（1）设计了一个半监督的管道，从视频中学习3D人体动力学。

（2）提出了一种全卷积结构，利用时间卷积来估计视频中的3D人体姿势。

（3）首先估计了每帧的2D关节位置和SMPL模型参数，并使用束调整估计平滑结果

（4）注于从标记帧和未标记帧学习特征，以执行密集的时间位姿传播和估计。

（5）提出了一种针对多帧场景的人体姿态估计方法，他们利用视频帧之间的时间信息来促进关键点检测。

2.2基于点云的深度学习

基于点云的方法主要以点云作为输入，可以从输入点云坐标和其他信息如表面或者其他信息中提取。

（1）点云分割分类

（2）将点云学习方法用于目标检测任务

（3）提出了PointNet的端到端网络，该网络使用点坐标和表面法线作为输入，并使用多层感知器将它们映射到高维空间。

（4）作者进一步使用了一个分区采样模块，并将输出递归地交给该模块。另一方面，他们还提出在混合相机中使用2D信息来加速3D检测

（5）提出了一种新方法，在对基于体素的表示进行卷积时，使用点来表示点云

（6）提出了一种可微分点云采样方法，可以预测采样中心，并实现了最先进的性能

区别：（1）我们提出了第一个基于点云序列的三维人体姿态估计框架，并提出了姿态一致性损失来平滑姿态估计结果

（2）在采样阶段引入注意机制，提高了三维姿态估计任务的性能。

3.方法

姿估计方法大致可以分为两部分：基于密度的点云采样模块和顺序的三维人体位姿估计模块。

（1）提出一种利用密度引导注意机制的可微点云采样

（2）三维人体姿态估计模块中，我们从采样的点云序列中估计出三维人体姿态，对点采样网络和三维人体姿态估计网络进行端到端训练

3.1点云采样模块

原始深度图包含冗余和噪声的像素，增加了计算成本，降低了人体姿态估计的精度。如果将背景像素或噪声像素混合到点云中进行人体姿态估计，那么人体姿态估计往往会出现较大的估计误差。我们通过设计一种带有密度引导注意机制的新型可微采样策略来解决这个问题。

步骤：

\1. 首先，我们的目标是用输入点云P生成一组采样中心R

使原始点云P中R的邻近点在人体姿态估计任务中表现更好

\2. 在采样中心R、预测权值wpred和原始点云的引导下对点云进行采样

3.2采样中心生成

期望输入点云中采样中心的邻近点云位于人体前景中

考虑了采样中心点与其邻域之间的关系

一种密度引导的注意机制，自适应生成采样结果

核心点往往是人的表面内部的点，边界点往往属于人的边界，那些既不是核心点也不是边界点的点通常不那么重要或有噪声，三维空间中是稀疏的，包含的人体姿态感知信息很少。

定义：r（核心点）距离和周围点数量

### **The TF operators are included under  `tf_ops`, you need to compile them first. Update  `nvcc`  and  `python`  path if necessary. The code is tested under TF1.15. If you are using earlier version it's possible that you need to remove the  `-D_GLIBCXX_USE_CXX11_ABI=0`  flag in g++ command(check `tf_xxx_compile.sh` under each ops subfolder) in order to compile correctly.**

 

 

 

# ***\*Wearable Motion Capture: Reconstructingand Predicting 3D Human Poses From\**** ***\*Wearable Sensors\****

可穿戴运动捕捉，从可穿戴传感器重建和预测3D人体姿态

 

摘要：

在无约束测量环境中重建和预测三维人体行走趋势，通过评估治疗后的进展并未辅助设备控制提供信息，有潜力用于运动残疾换则的健康检测系统。最新的姿态估计算法利用运动捕捉系统，从IMU传感器和第三人称视角相机捕捉数据。然而仅对门诊病人而言，第三人称视角并不总是可行的。因此我们提出来可穿戴式运动捕捉，即通过可穿戴IMU和穿戴摄像机重建和预测三维人体姿态，从而帮助临床医生对患者进行诊断。为了解决这一问题，引入新的面向注意力的循环神经网络，包含一个基于传感器的面向注意力的循环编码器，重建随时变化的三维人体姿态，预测一下时间步长的三维人体姿态

评估方法：使用可穿戴imu和可穿戴视频摄像机收集了一个新的可穿戴运动捕捉数据集，以及肌肉骨骼关节高度基准针织。提出A在新的下肢可穿戴运动捕捉数据集上显示出较高精度，而且它在两个公共全身姿态数据集上优于最先进的方法

介绍：运动障碍的人在行走时面临多种不利条件，如下背部的压力增加，代谢成本增加，不太不对称。适当检测行走的进展可以减轻这些缺点，并通过频繁评估即使随访治疗，预防继发问题，如关节炎，跌倒风险和血管疾病。目前的检测程序尽在临床现场可用。然而由于缺乏可行技术，对门诊出院后的治疗过程进行监控具有极大挑战性。因此有必要对门诊外的行走姿势进行评估，这不仅可以防止不必要的就诊，大大节省医疗开支，而且可以使患者在定期就诊之间即使得到适当治疗。

挑战：最常见的是，运动捕捉系统被用于实现对人体姿态的高精确理解，但大量的可穿戴标记和额外的运动捕捉相机在实验室中设置，使这种方法无约束的日常环境中不可行。

一些论文专注于从第三人称视角RGB或RGD-d相机中重建人体姿态。然而，这些基于第三人称视角的方法并不总是适用于门诊患者。因此，仅通过可穿戴传感器就需要对人体姿态进行重建和预测，使出院患者能够在日常生活中自由行走。

一些工作依赖于大量的IMU传感器，来获得精确的人体姿态重建，但佩戴大量传感器在日常生活中使用非常不舒服，和不切实际。最近一些作品使用了一组简化的IMU传感器来进行人体姿态重建。然而，稀疏惯性传感器的动作捕捉具有固有的模糊性和挑战性。

研究问题：上述挑战导致了一个研究问题：当出院患者在日常生活中行走时，如何设计一种可行有效的方法，通过一套小新的可穿戴传感器准确感知他们的姿态。因此，临床医生可以在诊所外访问或者的行走功能，研究人员可以设计智能假肢设备，以帮助门诊患者进行实时最佳控制。 

​	我们的贡献，如图1所示，提出了两个任务来处理可穿戴运动捕捉问题，1.随着时间的推移，重建3D人体互换姿态，用于临床诊断，预测一下时间不长的3D人体姿态，以时间实时辅助设备控制。

​	我们的方法说明，（a）我们的实验设置，（b）我们的目标，（c）提出的注意力党项循环神经网络的输入和输出。需要注意的是，之前的工作需要从第三人称视角获取视觉数据来进行姿态重建，在这，门诊患者并不总是可能时间的，与此相反，我们提出了在日常生活环境中重建和预测新购的随身相机和IMU传感器解决方案。

​	目前还没有包含可穿戴IMU和可穿戴相机数据的公共数据集，以及3D行走姿态基准真值，为了开发可穿戴运动捕捉算法，我们手机了10个不同不行速度的受试者在不同步行条件下的数据集，跑步机上，在地面上再留意上。虽然我们的合作研究项目针对下肢截肢患者，但我们的可穿戴运动捕捉也可以用于重建和预测上肢和全身姿态。因此，我们也比较了我们的可穿戴运动捕捉方法在两个相关的全身姿态数据集上的性能（DIP-IMU）包含10名受试者的IMU数据和TotalCapture包含了5名受试者的IMU数据和来自第三人称视角摄像机的视频。

贡献：

\1. 从可穿戴IMU传感器和可穿戴摄像机重建和预测三维人体姿态，

\2. 提出了一种新颖的注意力导向循环神经网络

\3. 引入了一个新的数据集，包含来自可穿戴IMU和可穿戴相机传感器的数据与3D人体姿态基准真值

基于IMU的人体动作捕捉:可穿戴imu在捕捉人体动作方面表现出显著稳定性和准确性

之前R引入IMU传感器

两个时间

 

![img](D:\Work_APP\Typora\assets\wps2.jpg) 

 

我们使用采集的下肢可穿戴IMU+相机数据集，可穿戴的动捕

 

#  

# ***\*Markerless vs. Marker-Based Gait Analysis: A Proof of Concept Study\****

 

无标记与基于标记的步态分析，一项概念证明研究

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

MotionBERT:学习人体动作表征的统一视角

一个统一视角来处理各种认为中心的视频任务。通过学习人体运动表示从大规模和异构的数据资源具体地说，我们提出了一个预训练阶段，其中一个运动编码器被训练从有噪声的部分2D观测中回复潜在的3D运动。通过这种方式获得的运动表示包含了关于人体运动的集合、运动学和物理知识，可以很容易地转移到多个下游任务。我们用一个双流时空转换器神经网络来是先运动编码器。该算法能够全面、自适应地捕捉骨骼关节之间的长时间空间关系，在从头开始训练时，其三维姿态估计误差最低。此外，我们提出的框架通过简单地微调带有简单回归的与旋律运动编码器，在所有三个下游任务上实现了最先进的性能。这表明了学习的运动表示的多功能性。

感知和理解人类活动一直是机器智能的核心追求。为此，研究人员定义了各种任务来从视频中估计以人为中心的寓意标签，例如骨架关节点、动作类和表面网络。虽然在这些任务重每一项都取得了重大进展，但他们往往是鼓励地建模而不是作为互相关联的问题。例如，时空卷积网络，在三维姿态估计、动作识别中被应用于人体关节时空关系建模，但它们之间的练习尚未得到充分探索。直觉上，这些模型都应该学会识别典型的人体运动模式，尽管他们针对不同的问题设计的。然而，当前的方法未能挖掘出利用这些任务之间的共性。理想情况下，我们可以开发一个统一以人为中心的视频表示，可以在所有相关人物之间共享。

开发这种表示的一个重大挑战是可用数据资源的异构性。动捕系统，提供了通过标记和传感器获得高保真的3D运动数据，但捕获的视频外观通常局限于简单的室内场景。动作识别数据集提供了动作寓意的朱姐，但他们要么不包含人体姿态标签，要么包含日常活动的受限动作。相比之下，在野外拍摄的人类视频提供了丰富多样的外观和动作。然而，获取精确的2D姿态标注需要相当大的工作量，而获取真值3D关节位置几乎是不可能的，因此现有的研究大多集中在使用单一类型的人体运动数据进行特定人物，无法享受其他数据资源的优势。

在这些工作中，我们为学习人体运动标准提供了一个新的视角。其关键思想是我们可以统一地从异构的数据资源中学习一种通用的人体运动表示，并利用该表示统一地处理不同的下游任务。我们提供了一个两阶段的框架，由与训练和微调组成，如图1所示，在训练前阶段，我们从不同的运动数据源中提取二维骨骼序列，并使用随机的遮罩和噪声破坏他们，然后，我们通过训练运动编码器从损坏的2D骨架中回复3D运动。这个挑战性的任务本质要求，从他的时间运动推断出潜在的3D人体结构，回复错误和确实的观测结果。通过这种方式，运动编码器隐含地捕捉人体运动常识，如关节连接，解剖约束和时间动力学。在实践中，我们提出了双流时空转换器作为运动编码器来捕捉骨架关键点之间的远程关系。我们假设，从大规模和多样化的数据资源中学习到的运动表示可以在不同的下游任务之间共享，从而有利于他们的可能性。因此，对于每个下游任务，我们使用任务特定的训练数据和带有简单回归头的监督信号来适应预先训练的运动表征。

综上所述，本研究的贡献在三个方面。1通过一个共享的人体运动表征学习框架，为解决各种以人为中心的视频任务提供一个新的视角。

2.我们提出了一种预训练方法来利用大规模而异质性的人体运动资源，学习可泛华的人体运动表征，我们的方法可以同时利用3D动作捕捉数据的精度和在户外RGB视频的多样性。

3.我们设计了一个具有级联时空自注意快的双流变压器网络可以作为人体运动建模的通用骨架。

实验表明上述设计能够实现多功能的人体运动表示，可传递到多个下游任务，优于任务特定的最先进方法。

基于骨骼的动作识别，

前人的工作只粗了动作识别与人体姿态估计之间的内在联系，对于人体关节时空关系的建模，比以往采用LSTM和GCN。最近，PoseConv3D提出将3D-CNN应用到堆叠的2D接缝热图上，得到改进

人体补网。基于SMPL等参数话人体模型，许多研究工作集中于从单个图像回归人体网络。SPIN额外地结合了适合的主体。

 

![img](D:\Work_APP\Typora\assets\wps3.jpg) 

时空转换器，DSTformer。

 

 

 

方法介绍：正如第一节所讨论的，我们的方法包括两个阶段，即统一的前训练和特定的微调。在第一阶段，我们训练一个运动编码器来完成2D到3D的提升任务，其中我们使用提议的DSTFORMER作为骨架。

第二阶段，我们微调了预训练的运动编码器和一些新的层下游的任务，我们使用2D 骨序列作为预训练和微调输入，因为他们可以可靠地从各种运动源中提取，并且对变化更鲁邦。现有研究表明，在不同下游任务中使用2D骨架序列是有效的。我们将首先介绍DSTformer作为骨干的体系结构，然后详细描述训练方案。

3.2网络架构。

 

 

 

问题：

1.

![img](D:\Work_APP\Typora\assets\wps4.jpg) 

![img](D:\Work_APP\Typora\assets\wps5.jpg) 

这边的特征点是啥？

\3. 这边正则化是啥目的是啥？

![img](D:\Work_APP\Typora\assets\wps6.jpg) 

\4. 什么是余弦相似度？

![img](D:\Work_APP\Typora\assets\wps7.jpg) 

\5. 使用属于相同和不同领域的负对是什么？

![img](D:\Work_APP\Typora\assets\wps8.jpg) 

\6. 泛化能力如何评估？

 

 

 

 

 

 

\7. 什么是Adam优化器？

 

![img](D:\Work_APP\Typora\assets\wps9.jpg) 

 

 

![img](D:\Work_APP\Typora\assets\wps10.jpg) 

 

# ***\*HUMAN3.6M数据集骨骼关节keypoint标注对应\****

（1）Top-Down（自上而下）方法

 

将人体检测和关键点检测分离，在图像上首先进行人体检测，找到所有的人体框，对每个人体框图再使用关键点检测，这类方法往往比较慢，但姿态估计准确度较高。目前的主流是CPN，Hourglass，CPM，Alpha Pose等。

 

（2）Bottom-Up（自下而上）方法

 

先检测图像中人体部件，然后将图像中多人人体的部件分别组合成人体，因此这类方法在测试推断的时候往往更快速，准确度稍低。典型就是COCO2016年人体关键点检测冠军Open 

https://blog.csdn.net/guyuealian/article/details/125502259

![img](D:\Work_APP\Typora\assets\wps11.jpg) 

![img](D:\Work_APP\Typora\assets\wps12.jpg) 

 

 

 

 

 

 

 

 

 

 

 

![img](D:\Work_APP\Typora\assets\wps13.jpg) 

 

 

 

 

![img](D:\Work_APP\Typora\assets\wps14.jpg) 

特征自动学习的功能

![img](D:\Work_APP\Typora\assets\wps15.jpg) 

https://ww.bilibili.com/video/BV1ZZ4y1R7m6

 

![img](D:\Work_APP\Typora\assets\wps16.jpg) 

 

 

 

![img](D:\Work_APP\Typora\assets\wps17.jpg) 

 

![img](D:\Work_APP\Typora\assets\wps18.jpg) 

 

 

 

 

人体姿态估计衍生问题：

单人多人问题，追踪问题，将2D关键点投射到3D表面上

Detectron2(facebook)

DensePose: Dense Human Pose Estimation In The

 

Densepose！！2D-3D

 

 

# ***\*Mediapipe\*******\*代码\****

![img](D:\Work_APP\Typora\assets\wps19.jpg) 

Mask 代表是不是人体

 

 

![img](D:\Work_APP\Typora\assets\wps20.jpg) 

x要乘以原图的宽度，y要乘以原图的高度获取归一化坐标

 

![img](D:\Work_APP\Typora\assets\wps21.jpg) 

对列表中的每个元素逐一用函数来操作

关键点的处理，因为

![img](D:\Work_APP\Typora\assets\wps22.jpg) 

 

对视频进行处理，pip追踪，有人体的，加快速度

![img](D:\Work_APP\Typora\assets\wps23.jpg)![img](D:\Work_APP\Typora\assets\wps24.jpg) 

 

 

 

 

 

 

 

 

# ***\*OpenCap:智能手机视频中的人体运动动力学\****

问题

1.肌肉激活、关节负荷和关节力矩对疾病风险的评估？ 

2.

 

 

关于mediapipe的学习

 

 

引入齐次坐标的意义

在透视空间里面，两条平行线可以相交，***\*平行线在透视空间的无穷远处交于一点，但是在欧氏空间却不能\*******\*。\****

齐次坐标就是用N+1维来代表N维坐标，加上一个额外的变量w来形成2D齐次坐标，一个点(X,Y)在齐次坐标里面变成了。

X = x/w

Y = y/w

(∞,∞)，然后它的齐次坐标表示为（1，2，0），因为(1/0, 2/0) = (∞,∞)，我们可以不用”∞"来表示一个无穷远处的点了

![img](D:\Work_APP\Typora\assets\wps25.jpg) 

![img](D:\Work_APP\Typora\assets\wps26.jpg) 

 

 

 

 

 

# ***\*2021轻量级人体姿态估计模型修炼之路\****

处理好数据、使用合适的Loss，随便用个剪枝后的轻量级模型都可以达到很高的精度.

调整模型输出、准备训练数据、修改DataLoader等,数据就用COCO和MPII就差不多了.

分类Accuracy、F1，检测常用mAP，一般是用PCK（PCKh）和OKS+mAP

 

 

肩关节角度测量的

# ***\*Validity and reliability of Kinect skeleton for measuring\**** ***\*shoulder joint angles: a feasibility study\****

***\*评估手段\****

类内相关系数(ICCs)、测量的标准误差和最小的可检测变化，确定了Kinect对肩部角度测量的绝对和相对测试-重测可靠性

计算了Kinect和测量肩部角度的标准方法之间95%的一致性限制(LOA)，以确定***\*并行\****有效性。

Kinect和两个测量标准之间的95% LOA大于±5◦在所有姿势的两种视图。

 

 

 

 

 

 

 

神奇的问题

互相调用就出问题，

![img](D:\Work_APP\Typora\assets\wps27.jpg) 

检测不到源文件中有这个变量报错

![img](D:\Work_APP\Typora\assets\wps28.jpg) 

 

 

 

 

 

 

# ***\*文献汇报，看的一些比较有趣的文献列表\****

 

1.

KeyTr: Keypoint Transporter for 3DReconstruction of Deformable Objects in Videos

KeyTr:用于视频中可变形对象的3D重构的关键点传输器

文章目的：我们考虑了从视频中重建动态物体深度的问题。动态视频深度预测的最新进展主要集中在通过多视图约束来改善单目深度估计器的输出，同时对场景的动态部分的变形施加很少或没有限制。然而，来自运动的非刚性结构理论规定了对3D重建的变形进行约束。因此，我们提出了一个与之前的工作有很大不同的新模型。其想法是使用Sinkhorn的算法将动态点云拟合到视频数据中，以将3D点与2D像素关联起来，并使用可微点渲染器来确保3D变形与测量光流的兼容性。通过这种方式，我们的算法，称为关键点传输器，在整个视频中对物体的整体变形进行建模，因此它可以相应地约束重建。与较弱的变形模型相比，这大大减少了重建的模糊性，对于动态对象，关键点传输器可以获得质量优于或至少与先前方法相当的重建，同时速度更快，依赖于预训练的单目深度估计器网络。为了评估该方法，我们对新的合成视频数据集进行了评估，这些视频描述了具有地面真实深度的动态人类和动物。我们还展示了对众包的真实世界宠物视频的定性结果。

 

2.

LifelongGlue: Keypoint matching for 3D reconstruction with continual neuralnetworks*

LifelongGlue:连续神经网络三维重建的关键点匹配*

人类通过不断的学习过程获得知识。他们从经验中学习，积累知识，并运用它来完成手头的任务。基于人工智能的系统的主要目标是产生人类大脑持续学习的能力。目前基于人工智能的自主系统在适当调节、良好调整和同质化的数据上表现良好。然而，对于大多数最先进的系统来说，当呈现多个基于任务的增量数据时，性能会受到抑制。在大脑学习的激励下，本文引入了LifelongGlue，这是一种用于3D重建图像之间关键点关联的持续学习神经网络。从视频或序列图像中对场景进行3D重建，在增强现实(AR)应用中起着至关重要的作用。关键点关联对于从多个视角对场景进行准确的姿态估计至关重要。目前开发的方法没有考虑视频连续帧之间的关系，并独立估计每对的关键点。我们提出的网络通过持续的自关注和交叉关注增强了局部特征的表达性，从而利用先前学习的知识实现了序列图像之间的精确点匹配。与传统和先前基于深度学习的方法相比，我们的方法在具有挑战性的室内和室外场景中获得了更高的姿态估计结果。我们的方法的性能在多个数据集上得到了验证。结果表明，所提出的方法优于最先进的匹配方法，同时获得了实质性的改进。

3.

Aperformance evaluation of keypoints detectionmethods SIFT and AKAZE for 3D reconstruction

关键点检测方法SIFT和AKAZE在三维重建中的性能评价

关键词:三维重建，关键点匹配，SIFT, AKAZE，多视点立体

摘要:本文讨论了多视点图像的三维重建。我们特别关注用于三维重建的关键点检测/特征描述符SIFT[1]和AKAZE[2]，并评估它们的性能。3D重建的质量高度依赖于图像之间的keypoint匹配结果，因此评估其性能非常重要。首先给出了SIFT和AKAZE算法的关键点匹配结果。接下来，根据每个匹配结果进行3D重建，并对3D点的精度进行评估。我们还使用了Multi View Stereo (CMVS[41])来获得密集的3D点。此外，在本研究中，我们提出了一种将SIFT和AKAZE相结合的新方法，以获得更详细的重建，并且显示出比单独使用SIFT或AKAZE更好的重建结果。

\4. BKinD-3D: Self-Supervised 3D Keypoint Discovery from Multi-View Videos 

BKinD-3D:多视点视频的自监督3D关键点发现

量化三维运动对于研究人类和其他动物的行为很重要，但手动姿势注释是昂贵和耗时的。自监督关键点发现是一种很有前途的策略，可以在没有注释的情况下估计3D姿势。然而，目前的关键点发现方法通常处理单个2D视图，而不能在3D空间中操作。我们提出了一种新的方法，从行为智能体的多视图视频中执行3D中的自监督关键点发现，而不需要在2D或3D中进行任何关键点或边界框监督。我们的方法BKinD-3D使用带有3D体积热图的编码器-解码器架构，经过训练可以重建多个视图之间的时空差异，此外还可以对已学习的主体3D骨架进行关节长度约束。通过这种方式，我们在人类和大鼠的视频中不需要人工监督就能发现关键点，展示了3D关键点发现在研究行为方面的潜力。

5.HoloPose: Holistic 3D Human Reconstruction In-The-Wild

HoloPose:野外整体3D人体重建

我们介绍了HoloPose，一种整体单眼三维人体重建方法。我们首先引入了一个用于3D模型参数回归的基于部分的模型，该模型允许我们的方法在野外操作，优雅地处理严重闭塞和大姿态变化。我们进一步训练了一个包含2D、3D和Dense Pose估计的多任务网络，以驱动3D重建任务。为此，我们引入了一种迭代改进方法，该方法将基于模型的2D/3D关节位置和DensePose的3D估计与CNN提供的基于图像的对应估计对齐，由于自下而上的CNN处理，实现了基于模型的全局一致性和高空间精度。我们在具有挑战性的基准测试上验证了我们的贡献，表明我们的方法允许我们获得准确的关节和3D表面估计，同时在野外以超过10fps的速度运行。有关我们方法的更多信息，包括视频和演示，请访问

在这项工作中，我们提出了HoloPose，一种使用人体形状的紧密先验模型与多种姿态估计方法相结合的方法，以获得精确的单目3D人体重建。我们已经考虑到人体的铰接性质，表明它在单片基线上大大提高了性能，并引入了一种改进程序，允许迭代地调整单镜头系统的形状预测结果，以满足互补的全卷积网络施加的几何约束。未来，我们打算探索神经网格合成模型;使用分布式表示可以更容易地适应多模态分布，包括男性、女性和儿童表面，这些表面目前由单独的形状模型处理。此外，我们的方法可以从更精确的几何建模中受益，例如通过结合透视投影、表面法线和轮廓信息[4]，而我们预计使用深度数据、多视图[18]或时间信息[53]可以帮助消除3D重建误差。

SMPL是一个真实的人体3D模型，基于皮肤和混合形状，并从数千个3D身体扫描中学习。这个网站提供了学习SMPL的资源，包括带有动画SMPL模型的示例FBX文件，以及在Python、Maya和Unity中使用SMPL的代码。

 

Densepose

人体表面的全方位观察，把每个人变成UV贴图，一片一片一片，一片。

系统可以覆盖浑身上下超过5000个节点，比十几个关节要细致得多。

6.Single-View 3D reconstruction: A Survey of deep learning methods☆

单视图三维重建:深度学习方法综述

在过去的五年中，使用深度学习技术的单视图3D形状重建和生成领域得到了快速发展。随着该领域达到成熟阶段，大量的方法不断被提出，目的是进一步推动研究状态。本文的重点是通过根据它们作为输出使用的形状表示对这些方法进行分类来调查文献。具体来说，它涵盖了每种方法的主要贡献、监督程度、训练范式，以及它与整个文献的关系。此外，本调查还讨论了该领域使用的常见3D数据集、损失函数和评估指标。最后，对目前的研究现状进行了深入的分析和反思，并对尚未解决的问题和可能的未来方向进行了总结。这项工作是向感兴趣的研究人员介绍数据驱动的单视图3D重建领域的努力，同时足够全面，可以作为已经在该领域进行研究的人的参考。

\8. What Do Single-view 3D Reconstruction Networks Learn?

单视图3D重建网络学习什么?

卷积网络在单视图对象重建中的表现令人印象深刻，并已成为一个热门的研究课题。所有现有的技术都统一在一个想法上，即拥有一个编码器-解码器网络，该网络对输出空间的3D结构进行非平凡的推理。在这项工作中，我们建立了两种替代方法，分别执行图像分类和检索。这些简单的基线在定性和定量上都比最先进的方法产生更好的结果。我们表明，编码器-解码器方法在统计上与这些基线无法区分，从而表明单视图对象重建中的当前技术状态实际上并没有进行重建，而是进行图像分类。我们确定了引起这种行为的流行实验程序的各个方面，并讨论了改进当前研究状态的方法。

 

\9. MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video

MixSTE: Seq2seq混合时空编码器，用于视频中3D人体姿态估计

最近提出了一种基于变压器的方法，通过全局考虑所有帧之间的身体关节来学习时空相关性，从2D关键点序列估计3D人体姿态。我们观察到不同关节的运动有显著差异。然而，以前的方法不能有效地模拟每个关节的实体帧间对应关系，导致对时空相关性的学习不足。我们提出了MixSTE (Mixed Spatio-Temporal Encoder)，它有一个时间变压器块来单独建模每个关节的时间运动，还有一个空间变压器块来学习关节间的空间相关性。这两个块交替使用，以获得更好的时空特征编码。此外，将网络输出从输入视频的中心帧扩展到整个帧，从而提高了输入和输出序列之间的一致性。在三个基准(即Human3.6M、MPI-INF-3DHP和HumanEva)上进行了广泛的实验。结果表明，我们的模型比最先进的方法高出10.9%的P-MPJPE和7.6%的MPJPE。代码可在https://github上获得。com/JinluZhang1126/MixSTE。

 

\10. Keypoint Transformer: Solving Joint Identification in Challenging Hands and Object Interactions for Accurate 3D Pose Estimation

关键点转换器:解决具有挑战性的手和物体交互中的关节识别，以实现准确的3D姿态估计

 

我们提出了一种鲁棒和精确的方法来估计在一个单一的彩色图像在密切互动的两只手的三维姿态。这是一个非常具有挑战性的问题，因为关节之间可能会发生大的咬合和许多混淆。最先进的方法通过回归每个关节的热图来解决这个问题，这需要同时解决两个问题:定位关节和识别关节。在这项工作中，我们提出通过依赖CNN首先将关节定位为2D关键点，并通过这些关键点上CNN特征之间的自关注将它们与相应的手部关节相关联来分离这些任务。由此产生的架构，我们称之为“关键点转换器”，效率很高，因为它在InterHand2.6M数据集上使用大约一半的模型参数就实现了最先进的性能。我们还表明，它可以很容易地扩展到估计由一只或两只手操纵的物体的3D姿态，并且具有高性能。此外，我们创建了一个新的数据集，其中有超过75000张双手操纵物体的图像，这些图像以3D方式进行了充分的注释，并将公开提供。

 

\11. Learnable Triangulation of Human Pose

人体姿态的可学习三角测量

 

 

 

 

 