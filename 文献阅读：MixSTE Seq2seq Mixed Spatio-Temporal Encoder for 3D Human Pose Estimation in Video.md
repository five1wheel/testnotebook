# 文献阅读：MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video

-  摘要部分

![开发流程图](D:\Work_APP\Typora\assets\开发流程图.png)

- 介绍部分

  应用：动作识别，虚拟人和人机交互。局限性：由于单目数据深度模糊性，多个潜在的3D姿态可以从同一个2D姿态映射，仅基于单帧2D关键点的信息难以回复准确的3D姿态。

![image-20240102102824065](D:\Work_APP\Typora\assets\image-20240102102824065.png)

​	本文贡献：

1. 提出了MixSTE来有效地捕获长序列中不同身体关节的时间运动，这有助于建模足够的时空相关性
2. 提出了一种新的交替设计与transformer-based seq 2seq模型来学习序列之间的全局一致性，以提高重建姿态的准确性。
3. 在三个基准上实现了最先进的性能，并具有出色的泛化能力。

- 相关工作

  - [x] 3D人体姿态估计

    单目数据估计3D姿态，依赖运动学特征和骨骼结构先验。主要分为端对端方式，和二维到三维提升方式。

    1. 端对端方式：直接从输入估计3D坐标，而无需中间2D姿态表示。

       缺陷：直接从图像空间回归，因此需要高计算成本

    2. 2D到3D提升：首先估计RGB数据中的2D关键点，然后利用2D和3D人体结构之间的对应关系将2D关键点提升到3D姿态

  - [x] 2D到3D提升下的Seq2frame和Seq2seq

    预测输入视频的中心帧，产生更具鲁棒的预测，和降低对噪声的敏感性。

    - [37]提出了基于时间卷积网络（TCN）的扩展时间卷积来提取时间特征

    - 通过利用注意力机制[28]改善TCN的性能

    - 将姿势估计任务分解为骨骼长度和骨骼方向预测[4]改善TCN的性能

      上述两个方法需要固定输入序列的感受野，本文方法优势：不需要预先设定每个输入的长度相对于卷积核或滑动窗口大小。

    - GCN也被运用通过图卷积网络估计3D姿态上

      上述方法统一的缺陷是计算冗余

    - seq2seq，提高3D姿态估计的一致有效性，一次性重建输入序列所以帧

      1. [15]引入LSTM来从一组2D关键点估计视频中的3D姿态
      2. [16]提出了一种时间导数损失函数来保证序列的时间一致性,但它面临着计算效率低的问题
      3. [46]利用了一种基于GCN的方法，并设计了相应的损失在短时间间隔和长时间范围内对运动进行建模，但它缺乏输入序列全局建模能力
      4. 本方法，具有时空域对每个关节全局建模能力，还支持矿建和关节的并行处理，解决了LSTM的低效率问题。

  - [x] 自注意力Transformer

    - [45]开始应用于各种视觉任务，例如视觉Transformer（ViT）
    - [10]进行分类，使用DETR进行检测
    - [49]提出转置从图像中估计2D姿态
    - [25]用于单个图像中恢复人体网络，和姿态估计----忽略了视频的时间信息
    - [14]多视图3D人体姿态估计，引入步幅Transformer编码器[23]，合并局部背景。
    - [57]PoseFormer构建了一个基于ViT的模型，以顺序捕获空间和时间依赖性。
    - [23]、[57]必须固定空间和时间编码器的顺序,并且只重建视频的中心帧。

    而本文方法用来类似的Transformer框架，但是考虑了不同身体关节的运动轨迹，并应用seq2seq来更好地实现模型序列的一致性。

    

- 方法介绍

  - 总体介绍

  1. 采取串联网络2D坐标，具有N个关节，T个帧，以下是输入的公式。通道数为2
     $$
     C _ { N , T }∈R ^ { N \times T \times 2 }
     $$

  2. 将输入关键点序列CN,T投影到高维特征
     $$
     P _ { N , T } ∈ R ^ { N \times T \times d _ { m } }
     $$
     dm表示联合表示的特征维数

  3. 利用位置嵌入矩阵来保留空间域和时间域的位置信息。所提出的MisSTE将PN,T作为输入，并旨在交替地学习空间相关性和分离的时间运动。

  4. 利用回归头对编码器的输出X进行拼接，并将维数dm取为3
     $$
     X ∈ R^{N \times T \times d m}→Out ∈ R^{N \times T \times 3}
     $$
     

  - 混合时空编码器（Mixed Spatio-Temporal Encoder）

  - 利用MixSTE分别为给定的2D输入关键点序列建模空间依赖性和时间运动。TTB和STB两个块。STB计算关节之间的自注意力，每帧关节关系，TTB计算帧间，每个关节全局相关性。

    - 分离时间相关学习

      时间维上将不同的关节分离，使得每个关节的运动轨迹都是一个单独的token（一个单独的单元，基本单位）
      $$
      X _ { i } ^ { t } = \operatorname { Concat }(F(P _ { i , 1 } , p _ { i , 2 } , \cdots p _ { i , T } ) ) ,  i∈ N
      $$
      把原方法PoseFormer的维度从N×dm降到dm，可以处理更长的序列

    - 空间相关学习

      STB学习每个帧关节之间的空间相关性。给定具有N个关节的2D关键点，我们将每个关节视为空间注意力机制的

      1. 将2D关键点作为输入，将每个关键点投影到具有线性嵌入层的高维特征

      2. 用位置矩阵（1），嵌入空间位置信息
         $$
         E _ { s - p o s } ∈ R ^ { N \times d m }（1）
         $$
         

      3. 将第i帧的空间tokens馈送STB空间自注意机制中，以对所有关节之间的依赖性进行建模，并在第i个STB钟输出最高维的tokens

    - 使用Seq2seq进行交替设计

      STB和TTB以交替方式设计，以编码不同的tokens。类似（递归神经网络RNN）

      可以联合时间维度上并行。我们堆叠STB和TTB用于dl循环，并且特诊的维度呗保留为固定大小dm，以保证时空相关学习集中在同一关节

      1. 仅在第一编码器中应用空间和时间位置嵌入以保留两种位置信息
      2. 存在时空域独立性，其中由于时空建模的单一过程，先前方法通常仅学习部分相关性。
      3. 获得更好的一致性和时空特征编码

      Seq2seq框架,为了更好地利用2D关键点的输入序列和3D姿态的输出序列之间的全局序列一致性。

      可以一次预测输入2D关键点的所有3D姿态,有助于保持输入和输出序列之间的序列一致性。

    - 模型中的Transformer模块
      $$
      ( Q , K , V ) = \operatorname { Softmax } ( \frac { Q K ^ { T } } { \sqrt { d m } } ) V
      $$

      $$
      M S A = \operatorname { C o n c a t } ( h e a d 1 , \cdots , h e a d _ { h } ) W ^ { O }
      $$

      $$
      head _ {i}= A t t e n t i o n ( Q _ { i } , K _ { i },V _ {i} ) , i ∈ h
      $$

      $$
      X = N o r m ( L _ { e } ( C _ { i } ) + E _ { p o s } ) , X∈ R ^ { N \times d m }
      $$

      $$
      R _ { s } = M S A ( U _ { Q } U _ { K } , U _ { K } ) + X
      $$

      $$
      U _ { i } = X W ^ { m } , m ∈ \{ Q , K , V \}
      $$

      

  - 实验

    应用了两种类型的2D联合检测数据，CPN 最典型的2D估计器，HRNet进一步研究我们方法的上限。15个动作的误差和平均误差，获得平均MPJPE为40.9mm的最佳结果，方案2下获得平均P-MPJPE为32.6mm的最佳结果。

    

  