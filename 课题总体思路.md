课题总体思路

RGB+D，估计人体姿态，做一些下游任务，比如疾病检测，康复训练指导

一、human3.6m数据集中的TOF数据处理、RGB图像处理倒出2D骨架模型。



首先将Directions 1.cdf的数据进行可视化，结果如下：

<img src="D:\Work_APP\Typora\assets\image-20240108202449854.png" alt="image-20240108202449854" style="zoom: 33%;" />

文件中的四个变量

![image-20240108202557628](D:\Work_APP\Typora\assets\image-20240108202557628.png)

存在的疑问是x3,x4（1,144,176,680）每个维度

问题解答：144*176是深度图片的大小，一共是1383帧，680代表不同的深度图，x3是保留背景的深度图，x4是去除背景的深度图。



随后，通过Alphapose、HRnet等导出2D关节点

<img src="D:\Work_APP\Typora\assets\image-20240109164801113.png" alt="image-20240109164801113" style="zoom:33%;" />

<img src="https://www.stubbornhuang.com/wp-content/uploads/2021/06/wp_editor_md_8b60abe0636eee8925dfa737317b832b.jpg" alt="姿态估计 – Halpe Full-Body136数据集骨骼关节keypoint标注对应-StubbornHuang Blog" style="zoom:33%;" />



在Alphapose的使用过程中发现coco 17关键点,Halpe *26关键点*和Halpe 136关键点，为了方便起见选择coco去进行训练。

将导出的17个关键点





二、进行RGB的投影

以下是 人体姿态估计及在康复训练情景交互中的应用[1]中的深度图生成点云阵后，与openpose结合生成三维关节点的过程

![image-20240109143835680](D:\Work_APP\Typora\assets\image-20240109143835680.png)



1)首先根据文献,对Kinect进行深度相机和彩色相机的内参标定。得到彩色相机的焦距为(fx_RGB,fy_RCB),中心点坐标为(Cx_RGB,Cy_RGB),内参矩阵为KRGB。深
度相机的焦距为(fsD,f,D),中心点坐标为(Cx_D,Cy_D),内
参矩阵为KD。
2)然后标定彩色相机和深度相机的变换关系,得到深度相机坐标系到彩色相机坐标系的旋转矩阵和平移向量分别为RD-RGB和tD-RGB。
3)根据深度相机的内参矩阵,可以将深度图像的二维坐标映射为深度相机坐标系下的三维坐标。设深度图像上的一点为(xp,yn),该点的深度值为depth(xp,yD),
则该点在深度相机坐标下的三维坐标(Xp,Yp,Zp)为:

![image-20240109145301406](D:\Work_APP\Typora\assets\image-20240109145301406.png)

4)结合式(1)将深度相机坐标下的三维坐标(XD,YD,ZD)转换成彩色相机坐标下的三维坐标(XRGB,YRGB,ZRGB)为:

![image-20240109145429863](D:\Work_APP\Typora\assets\image-20240109145429863.png)

5)进一步可得(XRGB,RGB,YRGB,ZRGB)在彩色图像坐标系下的坐标(xRGB,YRGB)为:

![image-20240109145809562](D:\Work_APP\Typora\assets\image-20240109145809562.png)

上述方案由于数据集通常缺少